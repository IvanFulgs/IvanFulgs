import requests
import json
import logging
import asyncio
import sqlite3
from bs4 import BeautifulSoup
from aiogram import Bot, Dispatcher, types, Router
from aiogram.enums import ParseMode
from aiogram.filters import Command
import os

# –í–∞—à —Ç–æ–∫–µ–Ω Telegram-–±–æ—Ç–∞
TOKEN = os.getenv("BOT_TOKEN")

bot = Bot(token=TOKEN)
dp = Dispatcher()
router = Router()

BASE_URL = "https://petition.president.gov.ua"
TARGET_VOTES = 25000
DB_FILE = "petitions.db"

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –±–∞–∑–∏ –¥–∞–Ω–∏—Ö
def init_db():
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute('''CREATE TABLE IF NOT EXISTS petitions (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        title TEXT,
                        votes_collected INTEGER,
                        days_remaining INTEGER,
                        url TEXT UNIQUE)''')
    conn.commit()
    conn.close()

def save_petition(petition):
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute('''INSERT OR IGNORE INTO petitions (title, votes_collected, days_remaining, url)
                      VALUES (?, ?, ?, ?)''',
                   (petition['title'], petition['votes_collected'], petition['days_remaining'], petition['url']))
    conn.commit()
    conn.close()

def get_petitions():
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    cursor.execute("SELECT title, votes_collected, days_remaining, url FROM petitions")
    petitions = cursor.fetchall()
    conn.close()
    return [{"title": row[0], "votes_collected": row[1], "days_remaining": row[2], "url": row[3]} for row in petitions]

def get_petition_info(url: str):
    response = requests.get(url)
    if response.status_code != 200:
        return None
    
    soup = BeautifulSoup(response.text, 'html.parser')
    title = soup.select_one("h1").text.strip()
    votes_collected = int(soup.select_one(".petition_votes_txt span").text.strip().replace(" ", ""))
    days_remaining_text = soup.select_one(".votes_progress_label").text.strip()
    days_remaining = int(''.join(filter(str.isdigit, days_remaining_text)))
    
    return {"title": title, "votes_collected": votes_collected, "days_remaining": days_remaining, "url": url}

@router.message(Command("gpetition"))
async def add_petition(message: types.Message):
    url = message.text.split(maxsplit=1)[1] if len(message.text.split()) > 1 else None
    if not url:
        await message.answer("–ë—É–¥—å –ª–∞—Å–∫–∞, –Ω–∞–¥–∞–π—Ç–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –ø–µ—Ç–∏—Ü—ñ—é.")
        return
    
    existing_petitions = get_petitions()
    if any(p['url'] == url for p in existing_petitions):
        await message.answer("‚ùå –¶—é –ø–µ—Ç–∏—Ü—ñ—é –≤–∂–µ –¥–æ–¥–∞–Ω–æ.")
        return
    
    petition_info = get_petition_info(url)
    if petition_info:
        save_petition(petition_info)
        await message.answer(f"‚úÖ –ü–µ—Ç–∏—Ü—ñ—è –¥–æ–¥–∞–Ω–∞!\n\nüìë <a href='{petition_info['url']}'>{petition_info['title']}</a>\nüìä –ì–æ–ª–æ—Å—ñ–≤ –∑—ñ–±—Ä–∞–Ω–æ: <b>{petition_info['votes_collected']}</b>\n‚è≥ –ó–∞–ª–∏—à–∏–ª–æ—Å—å –¥–Ω—ñ–≤: <b>{petition_info['days_remaining']}</b>", parse_mode=ParseMode.HTML)
    else:
        await message.answer("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–µ—Ç–∏—Ü—ñ—é.")

@router.message(Command("lpetition"))
async def list_petitions(message: types.Message):
    petitions = get_petitions()
    if not petitions:
        await message.answer("üìù –ù–∞—Ä–∞–∑—ñ –Ω–µ–º–∞—î –∂–æ–¥–Ω–æ—ó –¥–æ–¥–∞–Ω–æ—ó –ø–µ—Ç–∏—Ü—ñ—ó.")
        return
    
    result = "üìë <b>–°–ø–∏—Å–æ–∫ –ø–µ—Ç–∏—Ü—ñ–π:</b>\n\n"
    for p in petitions:
        result += f"üîπ <a href='{p['url']}'>{p['title']}</a>\nüìä –ì–æ–ª–æ—Å—ñ–≤ –∑—ñ–±—Ä–∞–Ω–æ: <b>{p['votes_collected']} –∑ 25000</b>\n‚è≥ –ó–∞–ª–∏—à–∏–ª–æ—Å—å –¥–Ω—ñ–≤: <b>{p['days_remaining']}</b>\n\n"
    
    await message.answer(result, parse_mode=ParseMode.HTML, disable_web_page_preview=True)

async def main():
    init_db()
    dp.include_router(router)
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
